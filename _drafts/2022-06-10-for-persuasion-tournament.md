---
layout: post
title:  "My GC and X-Risk Forecasts"
date:  2022-06-10 09:40:00 -0400
modified: 2022-06-26 09:41:00 -0400
permalink: "/for_persuasion_tournament/"
status: "Ongoing"
type: "Forecasting Log"
tags: [forecasting, prediction, gcr, x-risk, global-priorities]
image: /assets/2022/for_persuasion_tournament/birmingham-museums-trust-YHdOVC7mzkE-unsplash.jpg
description: "The extent of my participation in Philip Tetlock's Hybrid Forecasting Persuasion Tournament. There will be a separate post on the results of the tournament along with a post (perhaps the same post) that looks at the effectiveness of long-term forecasting."
---

__Overview__: _On 06/08/2022, I was invited to participate in Philip's Tetlock's Hybrid Forecasting-Persuasion Tournament. While I was not in the "core group of experts", I supposedly had enough "qualified background and experience" to participate, generally, and I looked forward to this event from an outside view. How difficult is it be for people to predict rares events ([global catastrophes][wiki_cata]) which, if they transpired, would be horrible for humanity? Recorded in this post are my thoughts, predictions, and reflections on the tournament as it occurred, posted $\geq 4$ months after the tournament was over._

[wiki_cata]: https://en.wikipedia.org/wiki/Global_catastrophic_risk "https://en.wikipedia.org/wiki/Global_catastrophic_risk"

--- 

## Table of Contents
{:.no_toc}
* TOC
{:toc}

---

## Structure 

![](/assets/2022/for_persuasion_tournament/stages.png)

<!-- ---

## Scoring  -->

---

## Questions 

### 1. Genetically Engineered Pathogen Risk (*)

> What is the probability that a genetically-engineered pathogen will be the cause of death, within a 5-year period, for more than 1% of humans alive at the beginning of that period...
- ...by the end of 2030?
- ...by the end of 2050?
- ...by the end of 2100?
> 
> Question and resolution details
> 
> - A pathogen is any microorganism (bacteria, viruses, etc.) that can cause diseases. 
- For the purposes of this question, an engineered pathogen is one produced via genetic modification or manipulation by humans. This may include the laboratory modification of pathogens that have previously been found in nature.
- In order to resolve positively, the relevant 5-year period must end before the resolution date.
- If reasonable people disagree about whether this event has occurred, this question will be resolved via a panel of experts.

#### Stage 1 

Denote e{YEAR} = "_a genetically-engineered pathogen will be the cause of death, within a 5-year period, for more than 1% of humans alive_" by [2031, 2051, 2101]. 

__Considerations__: As of (06/26/2022), there are around 7,956,600,000 billion people alive today[^world_o_meter1] - 1% of this is almost 80m people, so the temporally normalized perceived severity of this pandemic could "in 2022, a pandemic severe enough that 80m people die in the next 5 years". For context, as of (06/26/2022), there have been ~6.351m deaths[^deaths] from SARS-CoV-2[^world_o_meter2], which might have leaked from a laboratory[^leak], possibly following genetic modification.  There are ~8.5 years until the end of 2030, ~28.5 years until the end of 2050, and ~78.5 years until the end of 2100. 

[^leak]: https://en.wikipedia.org/wiki/COVID-19_lab_leak_theory "https://en.wikipedia.org/wiki/COVID-19_lab_leak_theory"

[^deaths]: This does not take into account excess deaths. "...taking into account likely COVID induced deaths via [excess deaths][wiki_excess], the 95% confidence interval suggests the pandemic to have caused between 14.7 and 24.9 millions deaths." See <https://en.wikipedia.org/wiki/COVID-19_pandemic_deaths>. 

[wiki_excess]: https://en.wikipedia.org/wiki/Mortality_displacement "https://en.wikipedia.org/wiki/Mortality_displacement"

[^world_o_meter1]: See <https://www.worldometers.info/world-population/>.

[^world_o_meter2]: See <https://www.worldometers.info/coronavirus/coronavirus-death-toll/>

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at <1%, of e2050 occurring at 3-5%, and of e2100 occurring a 7-20%.
-  Against 100 USD, I would bet 15k USD that e2030 does not occur, 4k USD that e2050 does not occur, and 500 USD that e2100 does not occur. 
- I would put the odds of e2030 between 1:800 and 1:7500, the odds of e2050 between 1:300 and 1:2500, and the odds of e2100 between 1:15 and 1:200. 
- Altogether: [0.005, 0.007, 0.0004] so 0.002 for e2030, [0.04, 0.024, 0.0012] so 0.01 for e2050, and [0.118, 0.167, 0.018] so 0.071 for e2100. With odds removed, these probabilities become 0.006, 0.03, and 0.14 for their respective events, which seems more in line with my attitudes. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- For 2030, my sense is that the odds are somewhere between 1:850 and 1:15000. The approx. geometric average of this is 1:(8.5+1.5)/2 x 10^(2+4)/2 = 1:5000 = 1/5001 = 0.0002 = ~0.02%. Going off of n = 8.5 trials with ~0.02% the constant annual probability would be p = ~0.0002, since 0.0002 = 1 - (1 - p)^{8.5}. Thus, for n = 28.5, p = 0.00568, and for n = 78.5, p = 0.01557. Without extrapolating, I would say that the odds of such a pandemic occurring before 2050 is 1:250 to 1:8000, and the odds for this occurring before 2100 are somewhere between 1:75 and 1:3000. The approximate geometric means of these values, respectively, are 3((2.5+8)/2)x10^{floor((2+3)/2)}= 1:1575 = 1/(1576) = 0.0006 = 0.06% for "by 2050". For "by 2100", we have ((7.5+3)/2)x10^{2} = 1:525 = 1/526 = 0.0019. See these numbers, I'm inclined to believe that these estimates don't align with my attiudes.  -->

<!-- There are presently alive, so 1% of this is this There are x years until 2030, y years until 2050, and z until 2100. The UN expects there to be  -->


 

<!-- __Relevant Links__: 
- <https://en.wikipedia.org/wiki/Pandemic_Severity_Assessment_Framework>
- <https://en.wikipedia.org/wiki/Pandemic_severity_index>
- <https://en.wikipedia.org/wiki/COVID-19_lab_leak_theory>
- <https://en.wikipedia.org/wiki/List_of_laboratory_biosecurity_incidents>
- <https://en.wikipedia.org/wiki/Gain-of-function_research>
- <https://en.wikipedia.org/wiki/Biosecurity>
- <https://en.wikipedia.org/wiki/Biorisk>
- <https://en.wikipedia.org/wiki/Biological_warfare>
- <https://en.wikipedia.org/wiki/Biological_Weapons_Convention>
- <https://en.wikipedia.org/wiki/Biodefense>
- <https://en.wikipedia.org/wiki/Bioterrorism>
- <https://en.wikipedia.org/wiki/Quarantine>
- <https://en.wikipedia.org/wiki/List_of_epidemics>
- <https://en.wikipedia.org/wiki/List_of_natural_disasters_by_death_toll#Deadliest_epidemics>
- <https://en.wikipedia.org/wiki/List_of_infectious_diseases>
- <https://en.wikipedia.org/wiki/Pandemic>
- <https://en.wikipedia.org/wiki/Epidemic>
- <https://en.wikipedia.org/wiki/Virulence>
- <https://en.wikipedia.org/wiki/Biological_agent>
- <https://en.wikipedia.org/wiki/Biological_hazard>
- <https://en.wikipedia.org/wiki/Laboratory_Response_Network>
- <https://en.wikipedia.org/wiki/Biosafety_level#Biosafety_level_4> -->


__Factors__: 
- Severity 
    - Population size 
    - Virulence 
    - 

<!-- __Scenarios__:
- Lab Leak
    - Lab 
    - Individual 
    - Company 
- Attack
    - State Sanctioned 
    - Terrorist 
        - Organization 
        - Individual 

__SPIES Naive__:  

__Other People's Attitudes__:

__Metaculus Community__: There are some notes from the Metaculus community on this. 

__Final Response__: 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  --> 

<!-- Naive Attitude:
Analogies: 
Distributions: 
Reciprocality: Predict what other researchers will do. Surprisingly popular answer. 
SPIES for this x 2:
<1
1-10
10-25 
25-40
40-80
80+ 
Summary 
What are they thinking I'm thinking?  -->



### 2. Non-Genetically Engineered Pathogen Risk (*)

> What is the probability that a non-genetically-engineered pathogen will be the cause of death, within a 5-year period, for more than 1% of humans alive at the beginning of that period...
- ...by the end of 2030?
- ...by the end of 2050?
- ...by the end of 2100?
>
> Question and resolution details
>
- A pathogen is any microorganism (bacteria, viruses, etc…) that can cause diseases.
- A naturally arising pathogen is any pathogen that was not produced via genetic modification or manipulation by humans. If there is a lab escape of a naturally arising pathogen that has not been genetically modified or manipulated (e.g. smallpox), this would count as a "naturally arising pathogen" for the purposes of this question. 
- In order to resolve positively, the relevant 5-year period must end before the resolution date.
- If reasonable people disagree about whether this event has occurred, this question will be resolved via a panel of experts.

#### Stage 1 

Denote e{YEAR} = "_a non-genetically-engineered pathogen will be the cause of death, within a 5-year period, for more than 1% of humans alive_" by [2031, 2051, 2101]. 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at <1%, of e2050 occurring at 1%, and of e2100 occurring a 3%.
-  Against 100 USD, I would bet 21k USD that e2030 does not occur, 6k USD that e2050 does not occur, and 1k USD that e2100 does not occur. 
- I would put the odds of e2030 between 1:3500 and 1:15000, the odds of e2050 between 1:2500 and 1:9000, and the odds of e2100 between 1:200 and 1:1500. 
- Altogether: [0.005, 0.0047, 0.0001] so 0.001 for e2030, [0.01, 0.016, 0.0002] so 0.003 for e2050, and [0.03, 0.091, 0.0018] so 0.017 for e2100. With odds removed, these probabilities become 0.0048, 0.0126, and 0.05 for their respective events. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- <!-- #### Stage 2 

#### Stage 3

#### Stage 4  --> 

### 3. AI Catastrophe Risk (*) 

> What is the probability that artificial intelligence will be the cause of death, within a 5-year period, for more than 10% of humans alive at the beginning of that period...
- ...by the end of 2030?
- ...by the end of 2050?
- ...by the end of 2100?
>
> Question and resolution details
> 
- Artificial intelligence is defined here as ‘the development of machines capable of sophisticated (intelligent) information processing (Dafoe 2018, AI Governance: A Research Agenda; See pg 5 footnote 2 for more.)
- We use the term “be the cause of death” to cover cases where AI is the direct or proximate cause of the deaths. For example, if a terminator-style robot powered by AI kills 10% of all humans alive at the time within a 5-year period, that will count for this question. Alternatively, if AI, operating without direct human intervention, causes the launch of nuclear weapons that kill 10% of all humans alive at the time, that will also count for the purposes of this question. And if that same incident does not kill 10% of all humans, but the subsequent nuclear winter does, that will also count for the purposes of this question.
- If reasonable people disagree about whether this event has occurred, this question will be resolved via a panel of experts.

#### Stage 1 

Denote e{YEAR} = "_artificial intelligence will be the cause of death, within a 5-year period, for more than 10% of humans alive_" by [2031, 2051, 2101]. 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at 1-7%, of e2050 occurring at 5-25%, and of e2100 occurring a 10-45%.
-  Against 100 USD, I would bet 8.5k USD that e2030 does not occur, 3k USD that e2050 does not occur, and 600 USD that e2100 does not occur. 
- Altogether: [0.0265, 0.0116] so 0.0175 for e2030, [] so 0.003 for e2050, and [] so  for e2100. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- <!-- #### Stage 2 

#### Stage 3

#### Stage 4  --> 

### 4. AI Extinction Risk (*) 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- <!-- #### Stage 2 

#### Stage 3

#### Stage 4  --> 

### 5. Nuclear Catastrophic Risk (*) 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__


<!-- <!-- #### Stage 2 

#### Stage 3

#### Stage 4  --> 



### 6. Nuclear Extinction Risk (*) 

#### Stage 1

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 7. Non-Anthropogenic Catastrophic Risk (*)

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 8. Non-Anthropogenic Extinction Risk (*) 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 9. Total Catastrophic Risk (*) 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 10. Total Extinction Risk (*) 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 11. Year of Extinction (*) 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 12. Future Human Births (*) 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

Use climate models + development models + birth models; then use scenarios other than business as usual to describe effects (look at analogies of births rates during WW2 or after catastrophes)

### 13. Non-Coronavirus mRNA Vaccine

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

__Source Notes__ 

__Quotes and Other Notes__ 

__Naive Attiude 2__ 

__Scenarios__ 

__Metaculus Community__

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 14. Novel Infectious Disease Surveillance System 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 15. Non-State Actor Bioweapon 1k Deaths

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 16. State Actor Bioweapon 1k Deaths 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 17. Non-State Actor Bioweapon 100k Deaths 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 18. State Actor Bioweapon 100k Deaths 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->


### 19. Lab Leaks 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 20. Individuals Countries with Biological Weapons Programs 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 21. Number of Countries with Biological Weapons Programs 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 22. PHEIC Declarations with 10k Deaths

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 23. Assassinations with Biological Weapons

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 24. Malaria Deaths 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 25. Average Global Surface Temperature

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 26. Cost of Utility-Scale Solar Energy 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 27. Nuclear Fusion Energy 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 28. Solar and Wind Energy 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 29. Annual Direct Air CO2 Capture

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 30. Cost of Hydrogen 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 31. Nuclear Weapon Use 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 32. Total Nuclear Warheads 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 33. Countries with Nuclear Warheads

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 34. Country-by-Country Nuclear Use 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 35. GPT Revenue 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 36. US GDP From Software 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 37. US Computer R&D Spending

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 38. Labor Force Partipication Rate in OECD

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 39. MATH Dataset Benchmark 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 40. "Massive Multitask Language Understanding" Benchmark

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 41. QuALITY Dataset Benchmark 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 42. AI Wins International Mathematical Olympiad

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 43. NYT Bestsellers Written by AI 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 44. Date of Advanced AI 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 45. Maximum Compute Used in an AI Experiment 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 46. Largest AI Experiment Cost of Compute

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 47. Lowest Price of GFLOPS 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 48. ImageNet Classification Training Efficiency

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 49. Largest Number of Parameters in a Machine Learning Model 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 50. Negative Public Opinion of AI 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 51. Nick Bostrom Affirms Existence of AGI 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 52. Probability of GDP Growth Over 15% 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 53. Year of GDP Growth over 15%

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 54. Loss of Agricultural Production 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 55. Space Colony 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 56. Happiness in America 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 57. Prevalence of Autocracies 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 58. Future Worries and Children 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

### 59. Generation Attitudes 

#### Stage 1 

__Naive Attitudes 1__: 
- I would put the probability of e2030 occurring at %, of e2050 occurring at %, and of e2100 occurring a %.
-  Against 100 USD, I would bet  USD that e2030 does not occur,  USD that e2050 does not occur, and USD that e2100 does not occur. 
- Altogether: [, ] so  for e2030, [, ] so  for e2050, and [, ] so  for e2100. 

<!-- #### Stage 2 

#### Stage 3

#### Stage 4  -->

--- 

## Appendix 

### Initial Survey Answers 

### SPIES Method 

### Forecasting Tools Employed 

<https://forecasting.wiki/wiki/Category:Making_good_forecasts>

> From "Superforecasting" (Appendix: Ten Commandments for Aspiring Superforecasters)
> 
> (1) Triage. (2) Break seemingly intractable problems into tractable sub-problems. (3) Strike the right balance between inside and outside views. (4) Strike the right balance between under- and overreacting to evidence. (5) Look for the clashing causal forces at work in each problem. (6) Strive to distinguish as many degrees of doubt as the problem permits but no more. (7) Strike the right balance between under- and overconfidence, between prudence and decisiveness. (8) Look for the errors behind your mistakes but beware of rearview-mirror hindsight biases. (9) Bring out the best in other and let others bring out the best in you. (10) Master the error-balancing cycle. (11) Don't treat commandments as commandments.

<https://www.bayesrulesbook.com/chapter-3.html>

<https://www.squiggle-language.com/playground/>

<https://en.wikipedia.org/wiki/Risk>

<https://safetysection.com/risk-assessment-calculation-formula/>

<https://intaver.com/blog-project-management-project-risk-analysis/risk-scores-2/>

<https://stats.stackexchange.com/questions/93523/how-do-we-predict-rare-events>

> The reason you are unlikely to get good results using classification or regression methods is that these methods typically depend on predicting the conditional mean of the data, and extreme events are usually caused by the conjunction of "random" factors all aligning in the same direction, so they are in the tails of the distribution of plausible outcomes, which are usually a long way from the conditional mean. What you can do is to predict the whole conditional distribution, rather than just its mean, and get some information on the probability of an extreme event by integrating the tail of the distribution above some threshold. I found this worked well in an application on statistical downscaling of heavy precipitation.

Exponential smoothing: 

<https://machinelearningmastery.com/exponential-smoothing-for-time-series-forecasting-in-python/>

<https://hbr.org/1971/07/how-to-choose-the-right-forecasting-technique>

--- 

## [Notes](#notes)

### *Cover Photo*

The [cover photo]() for this page was likely taken by [](). I found the photo on [Unsplash](https://unsplash.com/). To my knowledge, my use of this photo is permissible under Unsplash's [license](https://unsplash.com/license):
> Unsplash grants you an irrevocable, nonexclusive, worldwide copyright license to download, copy, modify, distribute, perform, and use photos from Unsplash for free, including for commercial purposes, without permission from or attributing the photographer or Unsplash. This license does not include the right to compile photos from Unsplash to replicate a similar or competing service.

### *Footnotes*