---
layout: post
title:  "Global Catastrophic and Extreme Risks"
date:  2022-03-27 12:14:00 -0500
permalink: "/gcr/"
status: "Notes"
certainty: "?"
importance: "?"
impact: "?"
tags: [gcr, global-priorities]
image: /assets/images/daniel_in_the_lions'_den_1965.13.1.jpg
desc: "My ongoing notes on global catastrophic risk (GCR) that I hope will one day metamorphose into a review. This post is primarily for my own learning."
---

## [Table of Contents](#toc)
{:.no_toc}
* TOC
{:toc}

Here are questions that I am accumulating in the subject[^1].

## [Nature](#nature)


## [Forecasts](#forecasting-gcr)

## [Resources](#resources)

### [Research Generators](#research-generators)

#### [Institutions](#institutions)

- __Future of Humanity Institute__; <https://www.fhi.ox.ac.uk/>
- __Future of Life Institute__; <https://futureoflife.org/>
- __Centre for Long-Term Resilience__; <https://www.longtermresilience.org/>
- __Global Catastrophic Risk Institute__; <https://gcrinstitute.org/>
- __Global Priorities Institute__; <http://www.globalpriorities.org/>
- __Forethought Foundation__; <https://www.forethought.org/>
- __World Health Organization__; <https://www.who.int/>
- __Global Challenges Foundation__; <https://globalchallenges.org/>
- __Open Philanthropy__; <https://www.openphilanthropy.org/>
- __Rethink Priorities__; <https://rethinkpriorities.org/>  
- __Global Priorities Project__; <http://globalprioritiesproject.org/>
- __Centre for Effective Altruism__; <https://www.centreforeffectivealtruism.org/>
- __Nuclear Threat Initiative__; <https://www.nti.org/about/programs-projects/project/global-catastrophic-biological-risks/>
- __Center for Health Security__; <https://www.centerforhealthsecurity.org/our-work/publications/global-catastrophic-biological-risks>
- __Global Catastrophic Risk Policy__; <https://www.gcrpolicy.com/understand>
- __ __; <>
- __ __; <>
- __ __; <>
- __ __; <>
- __ __; <>
- __ __; <>
- __ __; <>
- __ __; <>
- __ __; <>

#### [Individuals](#individuals)

- __Seth Baum__; <https://sethbaum.com/>


### [Literature Search](#academic-litearture)

|Platform|Title|Date|Author/s|Contribution|
|:---|:---|:---|:---|:---|
|Future of Humanity Institute|QNRs: Toward Language for Intelligent Machine|2021-08-21|K. Eric Drexler|"_Incremental development of QNR- based models can build on current methods in neural machine learning, and as systems mature, could potentially complement or replace today’s opaque, error-prone “foundation models” with systems that are more capable, interpretable, and epistemically reliable_"|
|Global Priorities Institute|Effective altruism, risk, and human extinction|2022-01-26|Richard Pettigrew|"_Any effort to ensure a long happy future will have to strive both to ensure a long future, by reducing extinction risks, and to ensure it is a happy one, by improving the quality of life. Such an effort might succeed at the former goal without succeeding at the latter._"|

<!-- ||||||
||||||
||||||
||||||
||||||
||||||
|||||| -->

## [Open Questions](#questions)

## [Glossary](#glossary)

## [Index](#index)

## [Notes](#notes)

#### *[Cover Photo](#cover-photo)*

The [cover photo](https://www.nga.gov/collection/art-object-page.50298.html). I found the photo on [National Gallery of Art](https://www.nga.gov/).

<!--
https://www.nga.gov/collection/art-object-page.66765.html -->

#### *[Footnotes](#footnotes)*

[^1]: What is a global catastrophic risk?; Which situations in humanity
