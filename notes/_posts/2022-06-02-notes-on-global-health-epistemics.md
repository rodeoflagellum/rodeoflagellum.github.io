---
layout: post
category: misc
title:  "EAF: \"Global health is important for the epistemic foundations of EA, even for longtermists\""
date:  2022-06-02 10:50:00 -0400
modified: 2022-06-02 10:55:00 -0400
permalink: "/notes_on_global_health_epistemics/"
description: "Some notes on Owen Cotton-Barratt's EAF post \"OGlobal health is important for the epistemic foundations of EA, even for longtermists\""
type: Thoughts
status: Unfinished
extent: (3/9)
durability: (3/5)
---


Thank you for contributing this. 

I believe from my experience that there is a tendency for longtermists to discount some pathways to good, especially those whose focus is on the short-term, without having seriously considered how clueless we are, if it semantically they know 

Here are some notes I've taken to try to put everything you've said together. Please update me if what I've written here omits certain things, or presents things inadequately. I've also included additional remarks to some of these things. 

- Central Idea: [EA's claim that some pathways to good are _much_ better than others] is not obvious, but widely believed (why?). 
    - Idea Support 1: The expected goodness of available actions in the altruistic market differs (across several orders of magnitude) based on the state of the world, which changes.
        - If the altruistic market of _any_ world state was made efficient (which EA might achieve), then the available actions with the highest expected goodness would routinely be located.  
    - Idea Support 2: Hindsight bias routinely warps our understanding of which investments, decisions, or beliefs were best made at the time, by having us believe that the best actions were more predictable than they were in actuality. It is plausible that this generalizes to altruism. As such, we run the risk of being overconfident that, despite the changing state of the world, the actions with the highest expected goodness presently will still be the actions with the highest expected goodness in the future, be that the long-term one or the near-term one.  
    - (why?): The cause-area of global health has well defined metrics of goodness, i.e. altruism within global health is likely close to being efficient. 
        - Idea Support 3: There is little cause to suspect that since altruism within global health is likely close to being efficient, altruism within other cause-areas are close to efficient or can be made efficient 
    - Idea Support 4: How well “it’s possible to do a lot of good with a relatively small expenditure of resources” generalizes beyond global health is unclear, and should likely not be a standard belief for other cause-areas. The expected goodness of actions in global health is contingent upon the present world state. 
    - Action Update 1: Given the altruistic efficiency and clarity within global health, and given people's support for it, it makes sense to introduce EA's altruist market in global health to newcomers; however, we should not "trick" them into thinking EA is solely or mostly about altruism in global heath - rather, we should frame EA's altruist market in global health as an example of what a market likely close to being efficient _might_ look like. 
    



