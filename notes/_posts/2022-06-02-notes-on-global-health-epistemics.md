---
layout: post
category: misc
title:  "EAF: \"Global health is important for the epistemic foundations of EA, even for longtermists\""
date:  2022-06-02 10:50:00 -0400
modified: 2022-06-02 10:55:00 -0400
permalink: "/notes_on_global_health_epistemics/"
description: "Some notes on Owen Cotton-Barratt's EAF post \"OGlobal health is important for the epistemic foundations of EA, even for longtermists\""
type: Thoughts
status: Finished
extent: (3/9)
durability: (3/5)
---


Thank you for contributing this. I enjoyed reading it and thought that it made some people's tendency in EA (which I might be imagining) to "look at other cause-areas with Global Health goggles" more explicit. 

Here are some notes I've taken to try to put everything you've said together. Please update me if what I've written here omits certain things, or presents things inadequately. I've also included additional remarks to some of these things. 

- __Central Idea__: [EA's claim that some pathways to good are _much_ better than others] is not obvious, but widely believed (why?). 
    - __Idea Support 1__: The expected goodness of available actions in the altruistic market differs (across several orders of magnitude) based on the state of the world, which changes over time.
        - If the altruistic market was made efficient (which EA might achieve), then the available actions with the highest expected goodness, which change with the changing state of the world, would routinely be located in _any_ world state.  
    - __Idea Support 2__: Hindsight bias routinely warps our understanding of which investments, decisions, or beliefs were best made at the time, by having us believe that the best actions were more predictable than they were in actuality. It is plausible that this generalizes to altruism. As such, we run the risk of being overconfident that, despite the changing state of the world, the actions with the highest expected goodness presently will still be the actions with the highest expected goodness in the future, be that the long-term one or the near-term one.  
    - __(why?)__: The cause-area of global health has well defined metrics of goodness, i.e. the subset of the altruistic market that deals with altruism in global health is likely close to being efficient. 
        - __Idea Support 3__: There is little cause to suspect that since altruism within global health is likely close to being efficient, altruism within other cause-areas are close to efficient or can even be made efficient, given their domain-specific uncertainies. Some things don't generalize. 
    - __Idea Support 4__: How well “it’s possible to do a lot of good with a relatively small expenditure of resources” generalizes beyond global health is unclear, and should likely not be a standard belief for other cause-areas. The expected goodness of actions in global health is contingent upon the present world state, which will change (as altruism in global health progresses and becomes more efficient, there will be diminishing returns in the expected goodness of the actions we take today to further global health)
    - __Action Update 1__: Given the altruistic efficiency and clarity within global health, and given people's support for it, it makes sense to introduce EA's altruist market in global health to newcomers; however, we should not "trick" them into thinking EA is solely or mostly about altruism in global heath - rather, we should frame EA's altruist market in global health as an example of what a market likely close to being efficient can look like. 
    



